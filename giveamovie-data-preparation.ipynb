{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data \n",
    "top1000 = pd.read_csv(r'C:/Users/gizli/Desktop/imdb_top_1000.csv')\n",
    "movies = pd.read_csv(r'C:/Users/gizli/Desktop/movies_metadata.csv')\n",
    "name = pd.read_table('C:/Users/gizli/Desktop/name.tsv',sep='\\t')\n",
    "crew = pd.read_table('C:/Users/gizli/Desktop/crew.tsv',sep='\\t')\n",
    "ratings = pd.read_table('C:/Users/gizli/Desktop/ratings.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and preparing data\n",
    "movies['genres'] = movies['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "movies['year'] = pd.to_datetime(movies['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)\n",
    "movies.year = movies.year.apply(lambda x: pd.NA if 'N' in str(x) else x)\n",
    "movies.vote_average = movies.vote_average.apply(lambda x: pd.NA if '0.0' in str(x) else x)\n",
    "movies.genres = movies.genres.apply(lambda x: pd.NA if '[]' in str(x) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dropna(subset=['genres'], how='all', inplace=True)\n",
    "movies.dropna(subset=['imdb_id'], how='all', inplace=True)\n",
    "movies.dropna(subset=['title'], how='all', inplace=True)\n",
    "movies.dropna(subset=['overview'], how='all', inplace=True)\n",
    "movies.dropna(subset=['year'], how='all', inplace=True)\n",
    "movies.dropna(subset=['runtime'], how='all', inplace=True)\n",
    "movies.dropna(subset=['vote_average'], how='all', inplace=True)\n",
    "movies.drop(columns=['adult', 'belongs_to_collection', 'budget', 'homepage', 'id', 'original_language', 'original_title', \n",
    "                     'popularity', 'poster_path', 'production_companies', 'production_countries', 'revenue', 'spoken_languages',\n",
    "                     'status', 'tagline', 'video', 'vote_count', 'release_date'], inplace=True)\n",
    "movies.genres = movies.genres.apply(lambda x:  \",\".join(x) )\n",
    "movies['year'] = movies['year'].astype(int)\n",
    "movies['runtime'] = movies['runtime'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating data and sorting movies based on IMDB rating\n",
    "ratings.rename(columns = {'tconst':'imdb_id', 'averageRating':'vote_average'}, inplace = True)\n",
    "movies = movies.merge(ratings,on='imdb_id',how=\"left\")\n",
    "\n",
    "movies.rename(columns={'vote_average_y':'average_rating'}, inplace=True)\n",
    "movies.drop([\"vote_average_x\", 'numVotes'],inplace=True,axis=1)\n",
    "movies = movies.sort_values('average_rating', ascending = False)\n",
    "movies.overview = movies.overview.apply(lambda x: pd.NA if 'No overview' in str(x) else x)\n",
    "movies = movies.dropna()\n",
    "movies = movies.reset_index()\n",
    "movies = movies.drop('index', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletion of movies whose overview phrases are at least 20 letters\n",
    "top_movies.drop(top_movies[top_movies['overview'].map(len) < 20].index, inplace=True)\n",
    "# Limiting data to the first 35000 movies\n",
    "top_movies = movies.iloc[:35000]\n",
    "top_movies.drop(top_movies[top_movies['year'] < 1969].index, inplace=True)\n",
    "top_movies.to_csv('top_movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing director and writer data\n",
    "crew.rename(columns = {'tconst':'imdb_id'}, inplace = True)\n",
    "crew = top_movies.merge(crew,on='imdb_id',how=\"left\")\n",
    "crew = crew.drop(['genres', 'overview', 'runtime', 'title', 'year', 'average_rating'], axis=1)\n",
    "crew.to_csv('crews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies = pd.read_csv(r'C:/Users/gizli/Desktop/top_movies.csv')\n",
    "crews = pd.read_csv(r'C:/Users/gizli/Desktop/crews.csv')\n",
    "\n",
    "crew_list = []\n",
    "directors = crews['directors']\n",
    "for director in directors:\n",
    "    director = director.split(\",\")\n",
    "    for person in director:\n",
    "        crew_list.append(person)\n",
    "\n",
    "writers = crews['writers'] \n",
    "for writer in writers:\n",
    "    person = writer.split(\",\")\n",
    "    for person in writer:\n",
    "        crew_list.append(person)\n",
    "        \n",
    "        \n",
    "crew_list = list(set(crew_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_data = {'nconst':crew_list}\n",
    "persons = pd.DataFrame(person_data)  \n",
    "persons = persons.merge(name,on='nconst',how=\"left\")\n",
    "persons = persons.drop(['birthYear', 'deathYear', 'primaryProfession', 'knownForTitles'], axis=1)\n",
    "persons.to_csv('persons.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting keywords from overview sentences and adding them to the data\n",
    "top_movies = pd.read_csv(r'C:/Users/gizli/Desktop/top_movies.csv')\n",
    "data = top_movies.dropna(subset=['overview'])\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "lda = LatentDirichletAllocation(n_components=3,random_state=101)\n",
    "\n",
    "keywords = []\n",
    "\n",
    "\n",
    "for i in range (data.shape[0]):\n",
    "    keyword = []\n",
    "    text = \"\"\n",
    "    text += data['overview'][i]\n",
    "    text=[text]\n",
    "    dtm  = cv.fit_transform(text)\n",
    "    lda_fit  = lda.fit(dtm)\n",
    "    for id_value, value in enumerate(lda_fit.components_):\n",
    "        for index in value.argsort()[-5:]:\n",
    "            keyword.append(cv.get_feature_names()[index])\n",
    "    keywords.append(list(set(keyword)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_data_new = {'keywords': keywords}\n",
    "keywords_data = pd.DataFrame(keywords_data_new)\n",
    "keywords_data.to_csv('keywords_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_data = {'imdb_id': top_movies.imdb_id, 'keywords': keywords}\n",
    "keywords = pd.DataFrame(keyword_data)\n",
    "keywords.keywords = keywords.keywords.apply(lambda x:  \",\".join(x) )\n",
    "keywords_new = pd.DataFrame(keyword_data)\n",
    "keywords_new.keywords = keywords_new.keywords.apply(lambda x:  \",\".join(x) )\n",
    "keywords_new.head()\n",
    "keywords_new.to_csv('keywords_new.csv', index=False)\n",
    "\n",
    "keywords['keywords'].str.split(',', expand=True).head(10)\n",
    "keywords = pd.concat([keywords['imdb_id'], keywords['keywords'].str.split(',', expand=True)], axis=1)\n",
    "keywords.rename(columns = {0:'keyword_1', 1:'keyword_2', 2:'keyword_3', 3:'keyword_4', 4:'keyword_5', \n",
    "                            5:'keyword_6', 6:'keyword_7', 7:'keyword_8', 8:'keyword_9', 9:'keyword_10', 10:'keyword_11'}\n",
    "                 , inplace = True)\n",
    "keywords.drop(['keyword_11'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicti = {}\n",
    "for i in range(len(keyword_data['imdb_id'])):\n",
    "    try:\n",
    "        dicti[keyword_data['imdb_id'][i]] = keyword_data['keywords'][i]\n",
    "    except KeyError:\n",
    "        continue\n",
    "        \n",
    "    \n",
    "df = pd.DataFrame(columns = ['imdb_id', 'keyword'])\n",
    "key_list = []\n",
    "for key in dicti:\n",
    "    for i in range (len(dicti[key])):\n",
    "        pair = []\n",
    "        pair.append(key)\n",
    "        pair.append(dicti[key][i])\n",
    "        key_list.append(pair)\n",
    "\n",
    "for key in key_list:\n",
    "    df.loc[len(df.index)] = [key[0], key[1]]\n",
    "df.to_csv('keywords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating genres from movies to another csv file\n",
    "genres = top_movies.genres\n",
    "imdb_id = top_movies.imdb_id\n",
    "for i in range(len(genres)):\n",
    "    try:\n",
    "        genres[i] = genres[i].split(\",\")\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "genre_dict = {}\n",
    "for i in range(len(imdb_id)):\n",
    "    genre_dict[imdb_id[i]] = genres[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = pd.DataFrame(columns = ['imdb_id', 'genre'])\n",
    "key_list = []\n",
    "for key in genre_dict:\n",
    "    for i in range (len(genre_dict[key])):\n",
    "        pair = []\n",
    "        pair.append(key)\n",
    "        pair.append(genre_dict[key][i])\n",
    "        key_list.append(pair)\n",
    "\n",
    "for key in key_list:\n",
    "    genre.loc[len(genre.index)] = [key[0], key[1]]\n",
    "genre.to_csv('genres.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = top_movies.genres\n",
    "genre_list = []\n",
    "for genre in genres:\n",
    "    for key in genre:\n",
    "        genre_list.append(key)\n",
    "        \n",
    "genre_list = list(set(genre_list))\n",
    "genres_data = {'genre': genre_list}\n",
    "genres_df = pd.DataFrame(genres_data)\n",
    "genres_df.to_csv('genre_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating director and writer csv file\n",
    "directors = crews.directors\n",
    "writers = crews.writers\n",
    "imdb_id = crews.imdb_id\n",
    "for i in range(len(directors)):\n",
    "    directors[i] = directors[i].split(\",\")\n",
    "    \n",
    "for i in range(len(writers)):\n",
    "    writers[i] = writers[i].split(\",\")\n",
    "\n",
    "director_dict = {}\n",
    "for i in range(crews.shape[0]):\n",
    "    director_dict[imdb_id[i]] = directors[i]\n",
    "    \n",
    "writer_dict = {}\n",
    "for i in range(crews.shape[0]):\n",
    "    writer_dict[imdb_id[i]] = writers[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director = pd.DataFrame(columns = ['imdb_id', 'director'])\n",
    "key_list = []\n",
    "for key in director_dict:\n",
    "    for i in range (len(director_dict[key])):\n",
    "        pair = []\n",
    "        pair.append(key)\n",
    "        pair.append(director_dict[key][i])\n",
    "        key_list.append(pair)\n",
    "\n",
    "for key in key_list:\n",
    "    director.loc[len(director.index)] = [key[0], key[1]]\n",
    "\n",
    "director.director = director.director.apply(lambda x: None if 'N' in str(x) else x)\n",
    "director.to_csv('director.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.DataFrame(columns = ['imdb_id', 'writer'])\n",
    "key_list = []\n",
    "for key in writer_dict:\n",
    "    for i in range (len(writer_dict[key])):\n",
    "        pair = []\n",
    "        pair.append(key)\n",
    "        pair.append(writer_dict[key][i])\n",
    "        key_list.append(pair)\n",
    "\n",
    "for key in key_list:\n",
    "    writer.loc[len(writer.index)] = [key[0], key[1]]\n",
    "\n",
    "writer.writer = writer.writer.apply(lambda x: None if 'N' in str(x) else x)\n",
    "writer.to_csv('writer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating keyword csv file\n",
    "keywords_data = pd.read_csv(r'keywords.csv')\n",
    "keyword_list = keywords_data.keyword\n",
    "keyword_list = set(keyword_list)\n",
    "keyword_data_df = pd.DataFrame(data=keyword_list, columns=['keywords'])\n",
    "keyword_data_df.to_csv('keyword_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
